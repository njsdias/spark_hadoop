# Sqoop Import

- Simple Import
- Execution life cycle
- Number of mappers

First we need to check if we have access to databases and tables because there
are privileges to access it. For that we can use the EVAL command and verify
if we can do a simple query.

It is important go to Sqoop Documentation and see the arguments for IMPORT
command and be familiarized with them.

    // running SQL SELECT queries using EVAL sqoop command
    sqoop eval\
      --connect jdbc:mysql://ms.itversity.com:3306/retail_db \
      --username retail_user \
      --password-file name_file \
      --query "SELECT * FROM order_items LIMIT 10"

    // import sqoop command
    sqoop import\
      --connect jdbc:mysql://ms.itversity.com:3306/retail_db \
      --username retail_user \
      --password-file name_file \
      --table table_name \
      --target-dir /user/username/sqoop_import/db_name/table_name

Other option instead of use *--target-dir* is use *warehouse-dir* that not needs
a folder with the *table_name* because it creates that folder for us:

      --warehouse-dir /user/username/sqoop_import/db_name

Note
- --table : table to read
- --target-dir : it is the HDFS location for here the data will be copied
- --warehouse-dir: it will create a directory with the table name and then copy the table into that

To validate the IMPORT process we can search for the folder in Hadoop cluster:

    // to see the folder with table_name
    hadoop fs -ls /user/username/sqoop_import/db_name

    // to see the files inside of the folder with table_name
    // the data was split in several part-m-id files
    hadoop fs -ls /user/username/sqoop_import/db_name/table_name

    // to see the data stored in these files
    hadoop fs -tail /user/username/sqoop_import/db_name/table_name/ part-m-id


# Execution life Cycle

Life cycle generates code. This code is nothing more a mapreduce code which is
typical Hadoop mapreduce which is nothing more than JAVA. This JAVA code is used
to import. For this, the code is complied in JAR file and submit this to perform
 the import.

 When you run the *sqoop import command* we see the line:

     Executing SQL statement: SELECT t.P FROM 'table_name' AS t LIMIT 1

This is used by *sqoop import* to understand the status of the data. This
record the table along the column name.Using the columns name it extracts
the metadata from columns. Using that information it generates the file
*table_name.java* that in sequence is compiled in a JAR file that is injected into
sqoop.

**An important** thing to mention is the sqoop uses threats that is called mappers.
This is nothing more than of the amount of files that sqoop splits uses to store
the information that are in the table.By default the number of mappers is four.
To evaluate the size of the table the sqoop uses the primary key information of
the table.

    SELECT MIN(order_item_id), MAX('order_item_id') FROM 'orders_items'

with *order_item_id* is the primary key of *orders_items* table

All information is in the line generated by sqoop import. This line contains an
url, like this one:

    http://website.com:port_number/proxy/application_id

where we can go to **Map Task** menu to see the details of map reduce.

If we can change the number of mappers we need to pass the argument *--num-mapers*.

    // import sqoop command
    sqoop import\
      --connect jdbc:mysql://ms.itversity.com:3306/retail_db \
      --username retail_user \
      --password-file name_file \
      --table table_name \
      --warehouse-dir /user/username/sqoop_import/db_name \
      --num-mappers 1

Important: Search for the implications to Database of increasing and decreasing
the number of mappers (avoid data redundancy).

# Managing Directories

Before to write into a directory check it is exists and if you are able to
delete information. If it is the case you can incorporate the command
*-- delete-target-dir* into IMPORT sqoop. It will delete the directory
and all content and creates new empty directory.

    // import sqoop command
    sqoop import\
      --connect jdbc:mysql://ms.itversity.com:3306/retail_db \
      --username retail_user \
      --password-file name_file \
      --table table_name \
      --warehouse-dir /user/username/sqoop_import/db_name \
      --num-mappers 1 \
      --delete-target-dir

In you want to add more files into an exist directory we can use *--append*
 parameter.

    // import sqoop command
    sqoop import\
     --connect jdbc:mysql://ms.itversity.com:3306/retail_db \
     --username retail_user \
     --password-file name_file \
     --table table_name \
     --warehouse-dir /user/username/sqoop_import/db_name \
     --num-mappers 1 \
     --append

To see the effects of this command it is only necessary to check the files in directory

    hadoop -fs -ls /user/username/sqoop_import/db_name/table_name
